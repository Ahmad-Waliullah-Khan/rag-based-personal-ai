# ğŸ§  F.R.I.D.A.Y: Your Personal, Private, File-Aware AI Assistant

**FRIDAY** is a local-first, customizable AI assistant inspired by Iron Man's AI companion.  
It runs entirely on your machine, respects your privacy, supports multi-turn conversations, reads your personal files (ebooks, notes, logs), and learns from them using vector search + Retrieval Augmented Generation (RAG).

Built with Python, Streamlit, ChromaDB, HuggingFace embeddings, and Ollama-powered LLMs.

---

## ğŸš€ Features

| Feature | Description |
|--------|-------------|
| ğŸ§µ Threaded chat sessions | Multi-turn conversations, saved per topic/thread |
| ğŸ“ File upload + embedding | Upload `.pdf` and `.txt` files; auto-embedded into memory |
| ğŸ§  RAG-powered QA | Ask questions about your notes, ebooks, and documents |
| ğŸ—ƒï¸ ChromaDB vector store | Fast, persistent vector search of embedded chunks |
| ğŸ” Smart re-embedding | Automatically skips files already embedded (hash caching) |
| ğŸ“– Chapter summarization | Summarize books and long texts by chapter |
| ğŸ“‚ File-specific querying | Limit your query to one file or query all at once |
| ğŸ§© Cross-RAG linking | Get related content across multiple files intelligently |
| ğŸ§‘ Persona customization | Rename your assistant + define its behavior |
| ğŸ’¬ Persistent chat memory | All messages and threads saved locally |
| ğŸ”’ 100% offline & private | All data stays on your machine; no external APIs |
| ğŸ“¦ Modular & extensible | Add Whisper input, journaling agents, or goal trackers later |

---

## ğŸ“ Project Structure
friday-ai/
â”œâ”€â”€ app.py                      # Main Streamlit app
â”œâ”€â”€ embed_utils.py             # Smart embedding logic w/ file hash detection
â”œâ”€â”€ summarizer_utils.py        # Chapter splitting and summarizing
â”œâ”€â”€ .gitignore                 # Ignore local files & DBs
â”œâ”€â”€ requirements.txt           # All Python dependencies
â”‚
â”œâ”€â”€ db/                        # Chroma vector database (auto-generated)
â”œâ”€â”€ my_context/
â”‚   â””â”€â”€ uploads/               # Your uploaded files go here
â”‚
â”œâ”€â”€ chat_threads.json          # Threaded chat memory
â”œâ”€â”€ file_hash_cache.json       # Embedded file hash cache



---

## âš™ï¸ Requirements

- Python 3.9+
- [Ollama](https://ollama.com/) installed with models like `phi3`, `mistral`, or `llama3`

---

## ğŸ”§ Installation

```bash
git clone https://github.com/Ahmad-Waliullah-Khan/rag-based-personal-ai
cd rag-based-personal-ai
python3 -m venv venv
source venv/bin/activate

pip install -r requirements.txt

streamlit run app.py
```
---



## Privacy by Design
- âœ… 100% local-first

- âŒ No OpenAI keys

- âŒ No third-party cloud calls

- ğŸ”’ All files, memory, and embeddings live inside your machine


## Contributions
Want to contribute? Suggest improvements, ideas, or fork and make it your own digital OS.